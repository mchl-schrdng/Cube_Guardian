{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGjo86eSVOWQ1qPFe1EnWF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mchl-schrdng/Cube_Guardian/blob/main/export_file.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcCf4j7uYx0x"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-bigquery google-cloud-storage paramiko pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_data = \"\"\"\n",
        "{\n",
        "  \"BIGQUERY_PROJECT\": \"redeemer-420917\",\n",
        "  \"BIGQUERY_DATASET\": \"export_to_ftp\",\n",
        "  \"TABLE_NAME\": \"data_to_export\",\n",
        "  \"DATE_COLUMN\": \"export_date\",\n",
        "  \"GCS_PROJECT\": \"rational-symbol-411613\",\n",
        "  \"GCS_BUCKET\": \"export_to_gcs\",\n",
        "  \"BASE_GCS_PATH\": \"data/\",\n",
        "  \"UPLOAD_FOLDER\": \"uploads/\",\n",
        "  \"ERROR_FOLDER\": \"errors/\",\n",
        "  \"FILENAME_PREFIX\": \"daily_data_export\",\n",
        "  \"FILE_EXTENSION\": \".csv\",\n",
        "  \"SFTP_DIRECTORY\": \"path/to/sftp/upload/\"\n",
        "}\n",
        "\"\"\"\n",
        "with open('config.json', 'w') as f:\n",
        "    f.write(config_data.strip())"
      ],
      "metadata": {
        "id": "y9pBrjM_e4It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['SFTP_HOST'] = 'your_sftp_host'\n",
        "os.environ['SFTP_USER'] = 'your_sftp_username'\n",
        "os.environ['SFTP_PASSWORD'] = 'your_sftp_password'"
      ],
      "metadata": {
        "id": "gbRTJnULZAL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import paramiko\n",
        "from google.cloud import bigquery, storage\n",
        "from datetime import datetime\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "\n",
        "# Configure detailed logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def load_config():\n",
        "    with open('config.json', 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "def authenticate_google_clients():\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/sa.json'\n",
        "    return bigquery.Client(), storage.Client()\n",
        "\n",
        "def fetch_data_from_bigquery(config, bigquery_client):\n",
        "    query = f\"SELECT * FROM `{config['BIGQUERY_PROJECT']}.{config['BIGQUERY_DATASET']}.{config['TABLE_NAME']}` WHERE DATE({config['DATE_COLUMN']}) = CURRENT_DATE()\"\n",
        "    try:\n",
        "        df = bigquery_client.query(query).to_dataframe()\n",
        "        logging.info(\"Data fetched successfully from BigQuery.\")\n",
        "        return df\n",
        "    except bigquery.exceptions.BigQueryError as e:\n",
        "        logging.error(f\"BigQuery error: {e.message}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def upload_file_to_gcs(config, storage_client, df):\n",
        "    if df.empty:\n",
        "        logging.error(\"DataFrame is empty. No data to upload.\")\n",
        "        return None\n",
        "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    filename = f\"{config['FILENAME_PREFIX']}_{current_date}{config['FILE_EXTENSION']}\"\n",
        "    file_path = os.path.join(config['BASE_GCS_PATH'], config['UPLOAD_FOLDER'], filename)\n",
        "    try:\n",
        "        blob = storage_client.bucket(config['GCS_BUCKET']).blob(file_path)\n",
        "        blob.upload_from_string(df.to_csv(index=False), content_type='text/csv')\n",
        "        logging.info(f\"File uploaded to GCS at {file_path}\")\n",
        "        return filename\n",
        "    except storage.exceptions.GoogleCloudError as e:\n",
        "        logging.error(f\"Failed to upload file to GCS: {e}\")\n",
        "        return None\n",
        "\n",
        "# def transfer_file_to_sftp(config, storage_client, filename):\n",
        "#     if not filename:\n",
        "#         logging.error(\"No filename provided for SFTP transfer.\")\n",
        "#         return\n",
        "#     remote_path = os.path.join(config['SFTP_DIRECTORY'], filename)\n",
        "#     try:\n",
        "#         with paramiko.Transport((os.getenv('SFTP_HOST'), 22)) as transport:\n",
        "#             transport.connect(username=os.getenv('SFTP_USER'), password=os.getenv('SFTP_PASSWORD'))\n",
        "#             with paramiko.SFTPClient.from_transport(transport) as sftp:\n",
        "#                 with StringIO(storage_client.bucket(config['GCS_BUCKET']).blob(os.path.join(config['UPLOAD_FOLDER'], filename)).download_as_string().decode('utf-8')) as file_stream:\n",
        "#                     sftp.putfo(file_stream, remote_path)\n",
        "#                 logging.info(f\"File transferred to SFTP at {remote_path}\")\n",
        "#     except paramiko.SSHException as e:\n",
        "#         logging.error(f\"SFTP transfer failed: {e}\")\n",
        "\n",
        "def main():\n",
        "    config = load_config()\n",
        "    bigquery_client, storage_client = authenticate_google_clients()\n",
        "    df = fetch_data_from_bigquery(config, bigquery_client)\n",
        "    filename = upload_file_to_gcs(config, storage_client, df)\n",
        "    # transfer_file_to_sftp(config, storage_client, filename)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "oY5oEpbCeP8K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}